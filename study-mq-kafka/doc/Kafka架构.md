# 1. 介绍

​		它是一个分布式的，支持多分区、多副本，基于 Zookeeper 的分布式消息流平台，它同时也是一款开源的基于发布订阅模式的消息引擎系统。

## 1.1 Kafka特性

1. 高吞吐、低延迟

   kakfa 最大的特点就是收发消息非常快，kafka 每秒可以处理几十万条消息，它的最低延迟只有几毫秒

2. 高伸缩性

   每个主题(topic) 包含多个分区(partition)，主题中的分区可以分布在不同的主机(broker)中

3. 持久性、可靠性

   Kafka 能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失，Kafka 底层的数据存储是基于 Zookeeper 存储的，Zookeeper 我们知道它的数据能够持久存储

4. 容错性

   允许集群中的节点失败，某个节点宕机，Kafka 集群能够正常工作；

5. 高并发

   支持数千个客户端同时读写

## 1.2 Kafka使用场景



# 2. 基本术语

1. 消息（Record）

   Kafka 中的数据单元被称为消息，也被称为记录，可以把它看作数据库表中某一行的记录

2. 主题（Topic）

   消息的种类称为主题，可以说一个主题代表了一类消息。相当于是对消息进行分类。主题就像是数据库中的表。主题是一个逻辑上的一个概念

3. 分区（Partition）

   

4. 生产者

   生产者就是消息的创造者，主要工作就是源源不断的产生消息，然后将其发送给消息队列，生产者可以发送各种消息给消息队列

5. 消费者

   

6. 代理

   

7. 消费者群组（Consumer Group）

   

8. 偏移量



# 3. 主题和分区

​		主题和分区是Kafka的两个核心概念。主题作为消息的归类，可以再分为一个或多个分区，分区也可以看做是对消息的二次归类。分区的划分不仅为Kafka提供了可伸缩性、水平扩展的功能，还通过副本机制来为Kafka提供数据冗余以提高数据可靠性。

​		从Kafka底层看，主题和分区是逻辑上的概念，分区可以有一至多个副本，每个副本对应一个日志文件，每个日志文件对应一至多个日志分段，每个日志分段还可以细分为索引文件、日志存储文件和快照文件

- 1主题：N分区
- 1分区：N副本
- 1副本：1日志文件
- 1日志文件：N日志分段

## 3.1 主题

### 3.1.1

### 3.1.2

## 3.2 分区

### 3.2.1 分区作用

1. 借助于分区，可以实现kafka的水平扩展

   ​		我们可以通过分区，将同一个主题下的消息保存在不同的kafka server上，当机器的运行能力不足时，只需要增加机器就可以了，在新的机器上创建分区，就可以实现水平扩展

2. 分区可以实现并行处理能力

   ​		当一个主题所发送的消息给该主题的所拥有的不同分区中，这样消息就可以实现并行发送和处理，由多个分区来接受信息

### 3.2.2 分区实现

​		分区中的消息数据是保存在日志文件当中的，分区在逻辑上对应一个日志，当生产者将消息写入到分区当中时，实际上是写入到了分区对应的日志中。而日志可以看做是一个逻辑上的概念，对应与磁盘上的一个目录，一个日志由多个Segment构成，每个Segment对应一个索引文件和日志文件。

### 3.2.3 存储结构

​		分区的数据存储在server.properties中配置的logs.dir路径下。如果一个主题下存在多个分区，那么每个分区就会对应一个目录，其目录的命名规则是topic + index，index是从0开始。

​		每个partion当中并不是由一个文件所构成的，因为随着消息数量的增加，如果分区当中的消息都保存在一个文件当中，显然是不够用的，kafka采用的是rolling log，也就是当分区当中的消息数量达到一定程度后，消息文件会进行分割，新的消息会被写到新的文件当中，而这一个个新的文件就叫做segment。

分割分区文件夹下面包含的文件如下

1. 0000000000000.index：这个文件是segment文件的索引文件，它与00000000000.log文件是成对出现的。
2. 0000000000000.log：这是segment文件的数据文件，用于存储实际的消息，该文件是二进制格式的，segment文件的命名格式是，分区的第一个segment从0开始，后续每个segment的文件名为上一个segment文件最后一个消息的offset值。没有数据就用0填充
3. 00000000000000.timeindex：该文件是一个基于日期的索引文件，主要是用在根据日期和时间来找寻消息的场景下，当然我们设置的文件过期时间也会基于这个日期的索引文件来确定哪些是过期的消息
4. leader-epoch-checkpoint：是一个leader的缓存文件

# 4 生产者

## 4.1 发送方式

1. ###  简单消息发送

2. ### 同步消息发送

3. ### 异步消息发送

## 4.2 分区机制

​		Kafka 对于数据的读写是以分区为粒度的，分区可以分布在多个主机（Broker）中。这样每个节点能够实现独立的数据写入和读取，并且能够通过增加新的节点来增加 Kafka 集群的吞吐量，通过分区部署在多个 Broker 来实现负载均衡的效果。

### 4.2.1分区策略

​		Kafka 的分区策略指的就是将生产者发送到哪个分区的算法。Kafka 为我们提供了默认的分区策略，同时它也支持你自定义分区策略。

1. 顺序轮询

   顺序分配，消息是均匀的分配给每个 partition，即每个分区存储一次消息。轮训策略是 Kafka Producer 提供的默认策略，如果你不使用指定的轮训策略的话，Kafka 默认会使用顺序轮训策略的方式。

2. 随机轮询

   随机轮询简而言之就是随机的向 partition 中保存消息。本质上看随机策略也是力求将数据均匀地打散到各个分区，但从实际表现来看，它要逊于轮询策略，所以如果追求数据的均匀分布，还是使用轮询策略比较好

3. 按照 key 进行消息保存

## 4.3 压缩机制

# 5 消费者

​		费者就是从kafka集群消费数据的客户端。单个消费者

## 5.1 消费者和消费者组

1. 什么是消费者组?

   单消费者模型时，当生产者产生的数据很快，超过了这个消费者的消费速度就会导致数据堆积。

   所谓消费者组，其实就是一组消费者的集合。一般来说一般来说都是采用消费者组来消费数据，而不会是单消费者来消费数据的。

   - 一个Topic可以被多个消费者组消费，并且每个消费者组互不干扰，每个消费者组都是完整数据
   - 一个分区只能被同一个消费者组内的一个消费者消费，而不能拆给多个消费者消费，也就是说一个消费者组内的消费者数比该Topic的分区数多，多余的消费者不起作用。

2. 一个消费组的消费者越多其消费能力就越强吗？

   不是。当消费者数大于分区数时，有些消费者没有数据消费。要想提高消费能力，除了添加消费者，分区的数量也是需要跟着增加的。只有这样他们的并行度才能上的去，消费能力才会强

3. 为了提高消费组的消费能力，是不是可以随便添加分区和消费者？

   不可以。一般来说，建议消费者数量额分区数量是一致的。当消费能力不够时，必须通过调整分区的数量来提高并行度，但是应该尽量避免这种情况发生。

   新增分区后，谁来消费，则Kafka会进行分区再平衡，来为这个分区分片消费者。分区分配期间，Topic是不可用的，并且作为一个被消费者，分区数的变动将影响每一个消费者组。所以在创建Topic的时候，尽量考虑好分区数。

## 5.2 消费方式

1. 队列
2. 订阅

## 5.3 分区再平衡

### 5.3.1 如何避免

1. 不正确配置导致
   - 消费者未能及时发送心跳，导致被borker踢出消费者组。这里可以设置 session.timeout.ms 超时时间 和 heartbeat.interval.ms 心跳间隔，一般可以把 超时时间设置为 心跳间隔的 3倍。
   - 消费者端无法在规定时间内消费完 poll 来的消息，消费者会自主离组。我们可以设置 max.poll.interval.ms 比处理时间略长
2. 分区新增或减少导致

# 6 Kafka 为何如此之快

Kafka 实现了零拷贝原理来快速移动数据，避免了内核之间的切换。Kafka 可以将数据记录分批发送，从生产者到文件系统（Kafka 主题日志）到消费者，可以端到端的查看这些批次的数据。批处理能够进行更有效的数据压缩并减少 I/O 延迟，Kafka 采取顺序写入磁盘的方式，避免了随机磁盘寻址的浪费，更多关于磁盘寻址的了解，请参阅 程序员需要了解的硬核知识之磁盘 。

总结一下其实就是四个要点

- 顺序读写
- 零拷贝
- 消息压缩
- 分批发送



